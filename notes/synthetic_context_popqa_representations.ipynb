{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"../src\" not in sys.path:\n",
    "    sys.path.insert(0, \"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-1003/APP/rag-memory-interplay/venv/lib/python3.9/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "from experiments import nethook\n",
    "from experiments.tools import make_inputs\n",
    "from experiments.utils import load_atlas\n",
    "\n",
    "from utils import read_json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-22-1003/APP/rag-memory-interplay/venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/contriever were not used when initializing Contriever: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing Contriever from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Contriever from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "SIZE = \"base\"\n",
    "# SIZE = \"large\"\n",
    "USERNAME_DIR = \"snic2022-22-1003\"\n",
    "SAVE_DIR = f\"/mimer/NOBACKUP/groups/{USERNAME_DIR}/APP/qa-retriever/exported\"\n",
    "QA_PROMPT_FORMAT = \"question: {question} answer: <extra_id_0>\"\n",
    "\n",
    "os.environ[\"WANDB_CACHE_DIR\"] = f\"/mimer/NOBACKUP/groups/{USERNAME_DIR}/OUTPUT/.cache/wandb\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"]= f\"/mimer/NOBACKUP/groups/{USERNAME_DIR}/OUTPUT/.cache/huggingface/transformers\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = f\"/mimer/NOBACKUP/groups/{USERNAME_DIR}/OUTPUT/.cache/huggingface/datasets\"\n",
    "\n",
    "reader_model_type = f\"google/t5-{SIZE}-lm-adapt\"\n",
    "model_path = f\"/mimer/NOBACKUP/groups/{USERNAME_DIR}/APP/qa-retriever/data/atlas/models/atlas_nq/{SIZE}\"\n",
    "model, opt = load_atlas(reader_model_type, model_path, n_context=1, qa_prompt_format=\"question: {question} answer: <extra_id_0>\")\n",
    "nethook.set_requires_grad(False, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_token_embedding(model, tokens):\n",
    "    inputs = make_inputs(model, tokens, prompt_is_dict=False)\n",
    "    \n",
    "    input_ids = inputs.input_ids.cuda().view(inputs.input_ids.size(0), -1)\n",
    "    attention_mask = inputs.attention_mask.cuda().view(inputs.attention_mask.size(0), -1)\n",
    "    decoder_input_ids = inputs.decoder_input_ids.cuda()\n",
    "\n",
    "    cfg = model.reader.encoder.config\n",
    "    cfg.n_context = inputs.input_ids.size(1)\n",
    "    cfg.bsz = inputs.input_ids.size(0)\n",
    "\n",
    "    with nethook.Trace(model, \"reader.encoder.embed_tokens\", stop=True) as t:\n",
    "        model.reader(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "        )\n",
    "\n",
    "    embeddings = t.output[:, :-1, :].detach().cpu().tolist()\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have #1\n",
      "{'question': \"What is George Rankin's occupation?\", 'answers': ['politician'], 'passages': [{'title': '', 'text': 'The occupation of George Rankin is politician.'}], 'subj': 'George Rankin', 'prop': 'occupation', 'obj': 'politician', 'views': {'s_pop': '142', 'o_pop': '25692'}, 'query': \"question: What is George Rankin's occupation? answer: <extra_id_0>\", 'gen_nocontext': 'a lawyer', 'gen_context': 'politician', 'gen_nocontext_matched': False, 'gen_context_matched': True, 'matched': False, 'prop_cf': [], 'subj_cf': ['Meg McCall', 'Nathan Purdee', 'Guy Joseph Bonnet', 'Gordie Gosse', 'Mariana Vicente', 'Henry Tizard', 'Henry Feilden', 'Kanye West', 'Pierre Pansu', 'Petru Vlah'], 'obj_cf': ['illustrator', 'model', 'musician', 'psychiatrist', 'lawyer', 'astronaut', 'financier', 'librarian', 'diplomat', 'revolutionary'], 'subj_cf_diff': ['Mary of Woodstock', 'Bad News Bears', 'Rakhyah District', 'Sandar IL', 'Pearl in the Crown', 'Violin Concerto', 'The Boss', 'Angel on the Right', 'The Black Unicorn', 'run batted in'], 'obj_cf_diff': ['Madrid', 'Lisbon', 'Armenia', 'Slovakia', 'Columbia', 'Kam', 'Austria', 'Manhattan', 'Lyon', 'Vienna']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 143.41it/s]\n"
     ]
    }
   ],
   "source": [
    "for data_path in glob.glob(\"../data/syn/popqa/data/matched-all/*.jsonl\"):\n",
    "    data = read_json_file(data_path, jsonl=True)\n",
    "    print(f\"We have #{len(data)}\")\n",
    "    print(data[0])\n",
    "\n",
    "    for row in tqdm(data):\n",
    "        subj_cf_emb = retrieve_token_embedding(model, row[\"subj_cf\"])\n",
    "        obj_cf_emb = retrieve_token_embedding(model, row[\"obj_cf\"])\n",
    "\n",
    "        row[\"subj_cf_emb\"] = subj_cf_emb\n",
    "        row[\"obj_cf_emb\"] = obj_cf_emb\n",
    "\n",
    "\n",
    "    save_path = \"/\".join(data_path.split(\"/\")[:-1]) + \"-repr/\" + data_path.split(\"/\")[-1]\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as fj:\n",
    "        for row in data:\n",
    "            fj.write(json.dumps(row) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c924a3b366f2428512e8119f66ee34e750cd77838d106b793d81686518d5af6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
